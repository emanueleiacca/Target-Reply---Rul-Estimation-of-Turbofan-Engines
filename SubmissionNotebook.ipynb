{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113912,"databundleVersionId":13573644,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndir_path = '/kaggle/input/target-reply-rul-estimation-of-turbofan-engines/'\ntrain_file = 'train_challenge.txt'\ntest_file = 'test_challenge.txt'\n\nindex_names = ['unit_nr', 'time_cycles']\nsetting_names = ['setting_1', 'setting_2', 'setting_3']\nsensor_names = ['s_{}'.format(i+1) for i in range(0,21)]\ncol_names = index_names + setting_names + sensor_names\n\ntrain = pd.read_csv((dir_path+train_file), sep=r'\\s+', header=None, names=col_names)\ntest = pd.read_csv((dir_path+test_file), sep=r'\\s+', header=None, names=col_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:08:49.933613Z","iopub.execute_input":"2025-09-04T10:08:49.933854Z","iopub.status.idle":"2025-09-04T10:08:52.295215Z","shell.execute_reply.started":"2025-09-04T10:08:49.933825Z","shell.execute_reply":"2025-09-04T10:08:52.294004Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Add RUL column in train dataset\ndef add_remaining_useful_life(df):\n    # Get the total number of cycles for each unit\n    grouped_by_unit = df.groupby(by=\"unit_nr\")\n    max_cycle = grouped_by_unit[\"time_cycles\"].max()\n\n    # Merge the max cycle back into the original frame\n    result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_nr', right_index=True)\n\n    # Calculate remaining useful life for each row\n    remaining_useful_life = result_frame[\"max_cycle\"] - result_frame[\"time_cycles\"]\n    result_frame[\"RUL\"] = remaining_useful_life\n\n    # drop max_cycle as it's no longer needed\n    result_frame = result_frame.drop(\"max_cycle\", axis=1)\n    return result_frame\n\ntrain = add_remaining_useful_life(train)\ntrain[index_names+['RUL']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:08:52.297216Z","iopub.execute_input":"2025-09-04T10:08:52.297848Z","iopub.status.idle":"2025-09-04T10:08:52.367489Z","shell.execute_reply.started":"2025-09-04T10:08:52.297812Z","shell.execute_reply":"2025-09-04T10:08:52.366430Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"       unit_nr  time_cycles  RUL\n0            1            1  148\n1            1            2  147\n2            1            3  146\n3            1            4  145\n4            1            5  144\n...        ...          ...  ...\n53754      260          312    4\n53755      260          313    3\n53756      260          314    2\n53757      260          315    1\n53758      260          316    0\n\n[53759 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_nr</th>\n      <th>time_cycles</th>\n      <th>RUL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>148</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>145</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>144</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53754</th>\n      <td>260</td>\n      <td>312</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>53755</th>\n      <td>260</td>\n      <td>313</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>53756</th>\n      <td>260</td>\n      <td>314</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>53757</th>\n      <td>260</td>\n      <td>315</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>53758</th>\n      <td>260</td>\n      <td>316</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>53759 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\n\nUNIT_COL, TIME_COL, RUL_COL = \"unit_nr\", \"time_cycles\", \"RUL\"\n\n# choose your window params\nW       = 50      # window length\nSTRIDE  = 5       # hop between windows \nMIN_W   = W       # enforce full windows\n\n# sensors/features to include INSIDE the window\nSENSOR_COLS  = [c for c in train.columns if c.startswith(\"s_\")]\nSETTING_COLS = [c for c in train.columns if c.startswith(\"setting_\")]\nREGIME_DUMMIES = [c for c in train.columns if c.startswith(\"regime_\")]\n\nBASE_IN_WIN = SENSOR_COLS + SETTING_COLS + REGIME_DUMMIES r\n\ndef extract_window_features(df_win: pd.DataFrame) -> dict:\n    \"\"\"\n    Causal features computed strictly inside the window.\n    Keep it simple to start; expand later if needed.\n    \"\"\"\n    out = {}\n    # simple stats per sensor\n    for s in SENSOR_COLS:\n        w = df_win[s].to_numpy()\n        out[f\"{s}_mean\"]   = float(np.nanmean(w))\n        out[f\"{s}_std\"]    = float(np.nanstd(w, ddof=0))\n        out[f\"{s}_last\"]   = float(w[-1])\n        # linear trend (slope) inside window (robust? can switch to Theil–Sen if you like)\n        x = np.arange(len(w))\n        if np.all(np.isfinite(w)) and len(w) >= 2:\n            slope = np.polyfit(x, w, 1)[0]\n        else:\n            slope = 0.0\n        out[f\"{s}_slope\"] = float(slope)\n\n    # include window-end settings/regime (use last value in window)\n    last = df_win.iloc[-1]\n    for c in SETTING_COLS + REGIME_DUMMIES:\n        out[c] = float(last[c]) if c in df_win.columns else 0.0\n\n    out[\"cycle_idx\"] = int(last[TIME_COL])\n    return out\n\ndef make_sliding_windows(df: pd.DataFrame,\n                         window=W,\n                         stride=STRIDE,\n                         min_w=MIN_W) -> tuple[pd.DataFrame, np.ndarray, np.ndarray]:\n    \"\"\"\n    Returns:\n      X_win: DataFrame of features\n      y_win: ndarray of RUL at window end\n      groups: ndarray of engine ids for GroupKFold\n    \"\"\"\n    rows = []\n    targets = []\n    groups = []\n\n    # ensure sorted\n    df = df.sort_values([UNIT_COL, TIME_COL])\n\n    for uid, g in df.groupby(UNIT_COL):\n        g = g.reset_index(drop=True)\n        n = len(g)\n        # slide over indices\n        start_idx = 0\n        while start_idx + min_w <= n:\n            end_idx = start_idx + window\n            if end_idx > n:\n                break  # require full window\n            win = g.iloc[start_idx:end_idx]\n\n            # label is RUL at window end (causal and well-defined in train)\n            rul_end = int(win[RUL_COL].iloc[-1])\n\n            feat = {\n                UNIT_COL: int(uid),\n                TIME_COL: int(win[TIME_COL].iloc[-1]),\n                \"rul_end\": rul_end\n            }\n            feat.update(extract_window_features(win))\n            rows.append(feat)\n            targets.append(rul_end)\n            groups.append(uid)\n\n            start_idx += stride\n\n    X_win = pd.DataFrame(rows).reset_index(drop=True)\n    y_win = np.asarray(targets, dtype=float)\n    groups = np.asarray(groups, dtype=int)\n    return X_win, y_win, groups\n\n# build training windows from TRAIN ONLY (train already has RUL)\nX_win, y_win, groups = make_sliding_windows(train)\nprint(X_win.shape, y_win.shape, groups.shape)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-04T10:08:52.371092Z","iopub.execute_input":"2025-09-04T10:08:52.371375Z","iopub.status.idle":"2025-09-04T10:09:46.200530Z","shell.execute_reply.started":"2025-09-04T10:08:52.371355Z","shell.execute_reply":"2025-09-04T10:09:46.199690Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(8298, 91) (8298,) (8298,)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"safe_solvers = [\"auto\", \"cholesky\", \"svd\", \"lsqr\"]\n\nridge_base = Pipeline([\n    (\"pre\", pre),\n    (\"model\", Ridge(random_state=0, max_iter=5000))\n])\n\nparam_grid = {\n    \"model__alpha\": np.logspace(-4, 3, 30),\n    \"model__solver\": safe_solvers,\n    \"model__fit_intercept\": [True, False],\n    \"model__tol\": [1e-4, 1e-3]  \n\ngs = GridSearchCV(\n    estimator=ridge_base,\n    param_grid=param_grid,\n    scoring={\"MAE\": mae_scorer, \"RMSE\": rmse_scorer, \"R2\": r2_scorer},\n    refit=\"RMSE\",\n    cv=cv,\n    n_jobs=-1,\n    return_train_score=True,\n    verbose=1\n)\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.base import clone\n\nparam_grid_pb = {\n    \"model__alpha\": np.logspace(-4, 3, 30),\n    \"model__solver\": [\"auto\", \"cholesky\", \"svd\", \"lsqr\"],  # no 'sparse_cg'\n    \"model__fit_intercept\": [True, False],\n    \"model__tol\": [1e-4, 1e-3]\n}\n\ngrid = list(ParameterGrid(param_grid_pb))\nresults = []\n\nfor params in tqdm(grid, desc=\"Ridge grid\", unit=\"cfg\"):\n    pipe = clone(ridge_base).set_params(**params)\n    try:\n        scores = cross_validate(\n            pipe, X_win[feat_cols], y_win, groups=groups, cv=cv,\n            scoring={\"MAE\": mae_scorer, \"RMSE\": rmse_scorer, \"R2\": r2_scorer},\n            return_train_score=False, n_jobs=-1, error_score=np.nan\n        )\n        rmse_mean = -np.nanmean(scores[\"test_RMSE\"])\n        mae_mean  = -np.nanmean(scores[\"test_MAE\"])\n        r2_mean   =  np.nanmean(scores[\"test_R2\"])\n        results.append({**params, \"RMSE\": rmse_mean, \"MAE\": mae_mean, \"R2\": r2_mean})\n    except ValueError:\n        # This config failed on all folds; record as NaNs and continue\n        results.append({**params, \"RMSE\": np.nan, \"MAE\": np.nan, \"R2\": np.nan})\n        continue\n\ndf_pb = pd.DataFrame(results)\ndf_pb_valid = df_pb.dropna(subset=[\"RMSE\"]).sort_values(\"RMSE\", ascending=True)\nprint(df_pb_valid.head(10))\n\nbest_params = df_pb_valid.iloc[0][[c for c in df_pb_valid.columns if c.startswith(\"model__\")]].to_dict()\nprint(\"Best (tqdm search) params:\", best_params)\n\nbest_pipe = clone(ridge_base).set_params(**best_params)\neval_model(best_pipe, f\"Ridge* (tqdm search) (W={W}, stride={STRIDE})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:15:39.316361Z","iopub.execute_input":"2025-09-04T10:15:39.316672Z","iopub.status.idle":"2025-09-04T10:18:14.965484Z","shell.execute_reply.started":"2025-09-04T10:15:39.316649Z","shell.execute_reply":"2025-09-04T10:18:14.964344Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Ridge grid:   0%|          | 0/480 [00:00<?, ?cfg/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54719d276ec340d3b617ae45fa92fbe3"}},"metadata":{}},{"name":"stdout","text":"    model__alpha  model__fit_intercept model__solver  model__tol       RMSE  \\\n51      0.000530                  True      cholesky      0.0010  32.261768   \n50      0.000530                  True      cholesky      0.0001  32.261768   \n49      0.000530                  True          auto      0.0010  32.261768   \n48      0.000530                  True          auto      0.0001  32.261768   \n52      0.000530                  True           svd      0.0001  32.261768   \n53      0.000530                  True           svd      0.0010  32.261768   \n67      0.000924                  True      cholesky      0.0010  32.262735   \n66      0.000924                  True      cholesky      0.0001  32.262735   \n65      0.000924                  True          auto      0.0010  32.262735   \n64      0.000924                  True          auto      0.0001  32.262735   \n\n          MAE        R2  \n51  24.097650  0.691261  \n50  24.097650  0.691261  \n49  24.097650  0.691261  \n48  24.097650  0.691261  \n52  24.097650  0.691261  \n53  24.097650  0.691261  \n67  24.110594  0.691243  \n66  24.110594  0.691243  \n65  24.110594  0.691243  \n64  24.110594  0.691243  \nBest (tqdm search) params: {'model__alpha': 0.0005298316906283707, 'model__fit_intercept': True, 'model__solver': 'cholesky', 'model__tol': 0.001}\n[Ridge* (tqdm search) (W=50, stride=5)]  R2 0.6913±0.0138  RMSE 32.262±0.785  MAE 24.098±0.511\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def last_full_window_per_engine(df_test: pd.DataFrame, window=W) -> pd.DataFrame:\n    rows = []\n    for uid, g in df_test.sort_values([UNIT_COL, TIME_COL]).groupby(UNIT_COL):\n        g = g.reset_index(drop=True)\n        if len(g) < window:\n            # OPTION: allow partial window for small engines\n            win = g.iloc[:]  # partial\n        else:\n            win = g.iloc[-window:]\n        feat = {\n            UNIT_COL: int(uid),\n            TIME_COL: int(win[TIME_COL].iloc[-1]),\n        }\n        feat.update(extract_window_features(win))\n        rows.append(feat)\n    return pd.DataFrame(rows).reset_index(drop=True)\n\nX_test_win = last_full_window_per_engine(test, window=W)\nX_test_feat_cols = [c for c in X_test_win.columns if c not in [UNIT_COL, TIME_COL]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:20:31.842057Z","iopub.execute_input":"2025-09-04T10:20:31.842431Z","iopub.status.idle":"2025-09-04T10:20:33.557866Z","shell.execute_reply.started":"2025-09-04T10:20:31.842405Z","shell.execute_reply":"2025-09-04T10:20:33.556992Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"best_ridge = Ridge(\n    alpha=0.0005298316906283707,\n    solver=\"cholesky\",\n    fit_intercept=True,\n    tol=1e-3,\n    random_state=0\n)\n\npre = ColumnTransformer([(\"scaler\", StandardScaler(), feat_cols)], remainder=\"drop\")\npipe = Pipeline([(\"pre\", pre), (\"model\", best_ridge)])\n\n# Fit on ALL training windows, then predict on the test last-window features\npipe.fit(X_win[feat_cols], y_win)\n\ny_pred_test = pipe.predict(X_test_win[feat_cols])\n\npred_df = pd.DataFrame({\n    \"unit_nr\": X_test_win[UNIT_COL].astype(int),\n    \"RUL\": np.clip(np.round(y_pred_test).astype(int), 0, None)\n}).sort_values(\"unit_nr\")\n\npred_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:20:34.271998Z","iopub.execute_input":"2025-09-04T10:20:34.272360Z","iopub.status.idle":"2025-09-04T10:20:34.341311Z","shell.execute_reply.started":"2025-09-04T10:20:34.272334Z","shell.execute_reply":"2025-09-04T10:20:34.340395Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   unit_nr  RUL\n0        1   41\n1        2  127\n2        3  113\n3        4   97\n4        5   12","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_nr</th>\n      <th>RUL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21}]}